+++
title = "GPT 3"
date = 2023-01-13T15:26:00+08:00
lastmod = 2023-01-15T11:11:21+08:00
draft = false
+++

-   [#57：拥有 1700 亿个参数的GPT-3， 人工智能史上的最大发明！？ - YouTube](https://www.youtube.com/watch?v=utPHXsB5bws)
-   TOC: Transformer, BERT, GPTs
    -   NLP Tasks
    -   RNN
    -   CNN
    -   Transformer
    -   BERT
    -   GPT-2
    -   GPT-3
-   Summary:
    -   RNN, CNN 的提出时间都比较久远了
    -   Transformer 是一个新的效果比较好的模型, BERT 与 GPT 都是基于 Transformer 的
    -   所谓大力出奇迹, GPT-3 就是这句话最好的验证.
    -   虽然效果很好, 但毕竟只是通过样本进行训练, 无法进行创作, 而创作则是人类区别与 AI 重要特点
-   Q&amp;A:
    -   因果关系的推理比较难, 因为实际上人的推理也不一定准确, 不用说 AI 了.
        -   机器学习其实是相关性, 而不是推理
    -   没必要把 AI 称神
    -   竞争太激烈了, 如果自己发现了新东西不发布, 可能后面就有人做出类似的东西来了
    -   如果处理隐喻?
        -   就是看训练集里面有没有对应的
    -   生活中的 AI: Grammarly, 猿题库拍照解题
